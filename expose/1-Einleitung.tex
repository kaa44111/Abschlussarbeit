\chapter{Einleitung}\label{sec:exp_einleitung}
Die industrielle Bildverarbeitung hat sich zu einer Schlüsseltechnologie in modernen Fertigungsprozessen entwickelt. Sie ermöglicht die automatisierte Inspektion, Qualitätskontrolle und Prozessoptimierung, wodurch Effizienzsteigerungen und Kostensenkungen erreicht werden können. Durch den Einsatz von Kamerasystemen und spezialisierter Software werden visuelle Informationen erfasst und analysiert, um beispielsweise Defekte frühzeitig zu erkennen, die Position von Objekten zu bestimmen oder Produktionsabläufe zu überwachen (Cognex, 2023). (https://www.cognex.com/de-de/what-is/machine-vision)

Mit der zunehmenden Komplexität industrieller Produkte und Prozesse steigen jedoch auch die Anforderungen an Bildverarbeitungssysteme. Besonders herausfordernd sind Szenarien, in denen Bilder durch Rauschen oder andere Störeffekte beeinträchtigt sind. Eigenschaften wie spezielle Texturen, Formen, Farben oder Größen von Objekten können die zuverlässige Detektion erschweren, da Fehler mit dem Hintergrund verschmelzen und somit eine präzise Analyse verhindern. Bildrauschen kann die Genauigkeit der Objektdetektion erheblich beeinträchtigen, was zu fehlerhaften Inspektionen und potenziellen Qualitätsproblemen führt.

Convolutional Neural Networks (CNNs) haben sich als leistungsfähige Werkzeuge in der Bildverarbeitung etabliert, da sie komplexe Muster und Strukturen in Bilddaten erkennen können \cite{lecun_deep_2015}. Ein besonderer Fokus liegt auf der semantischen Segmentierung, bei der jedem Pixel eines Bildes eine Klasse zugewiesen wird, was eine detaillierte Analyse und Interpretation ermöglicht \cite{long_fully_2015}.

Das U-Net-Modell ist eine spezialisierte Architektur von CNNs, die ursprünglich für die biomedizinische Bildsegmentierung entwickelt wurde \cite{ronneberger_u-net_2015}. Aufgrund seiner Fähigkeit, auch mit begrenzten Daten und in schwierigen Umgebungen präzise Ergebnisse zu liefern, hat es sich in verschiedenen Anwendungsbereichen bewährt. Die Anwendung von U-Net in industriellen Kontexten, insbesondere unter herausfordernden Bedingungen wie starkem Bildrauschen, bietet vielversprechende Möglichkeiten, die Leistungsfähigkeit von Bildverarbeitungssystemen zu steigern.

\section{Motivation}
Während meines Praxissemesters bei der Gefasoft GmbH in Regensburg hatte ich die Gelegenheit, an Projekten der industriellen Bildverarbeitung zu arbeiten. Dabei kamen verschiedene traditionelle Methoden zum Einsatz, wie Schwellenwertverfahren, Kantendetektion, Regionenwachstum, Watershed-Algorithmus und Clustering-Verfahren. Diese Methoden sind unerlässlich für eine erfolgreiche Bildsegmentierung, Objektdetektion und Bildklassifikation. \cite{suse_bildverarbeitung_2014,szeliski_computer_2022}Die Grundidee besteht darin, Bildinformationen zu vereinfachen, um nachfolgende Analysen zu erleichtern und die Komplexität zu reduzieren.Erfolgreiche Segmentierung, die für eine effiziente Bildanalyse entscheidend ist, beinhaltet die Aufteilung des Bildes in homogene Regionen. Sie spielt eine wesentliche Rolle bei der Objekterkennung und der Abgrenzung von Grenzen, indem Pixeln mit gemeinsamen visuellen Merkmalen identifiziert werden können.\cite{jahne_digitale_2024}.Diese Ansätze sind attraktiv, da sie keine komplexen Architekturen oder hohen Rechenaufwand erfordern und oft leicht zu implementieren sind. 

Jedoch wurde ich bei der Anwendung dieser Methoden auch mit deren Herausforderungen bekannt. Insbesondere bei stark verrauschten Bildern und geringem Kontrast zwischen Defekt und Hintergrund lieferten sie keine zufriedenstellenden Ergebnisse. Feine Defekte, wurden häufig nicht erkannt, da sie sich kaum vom Hintergrund unterschieden und das Rauschen die relevanten Signale überlagerte.Die traditionellen Methoden sind stark auf manuell gestaltete Merkmale und Heuristiken angewiesen, was arbeitsintensiv ist und ihre Anpassungsfähigkeit an neue oder veränderte Bedingungen einschränkt. Zudem erreichen sie im Vergleich zu modernen Verfahren oft eine geringere Genauigkeit und Effizienz, insbesondere bei komplexen Aufgabenstellungen. \cite{zhao_object_2019} -> Anmerkung vielleicht ein paar Bilder und Fälle die dir begegnet sind.

Diese Einschränkungen sind für meine Arbeit von besonderer Bedeutung, da die zuverlässige Erkennung von Defekten in stark verrauschten Bildern für die Qualitätssicherung in industriellen Prozessen entscheidend ist.

Im Gegensatz zu traditionellen Methoden lernen Deep-Learning-methoden, ins besondere Convolutional Neuronal Networks (CNNs),  automatisch, komplexe Merkmale aus Bildern zu extrahieren. Diese Fähigkeit ermöglicht es den Modellen, sich ohne manuelle Merkmalsauswahl an eine Vielzahl von Aufgaben anzupassen, was zu robusteren und skalierbareren Lösungen führt \cite{mo_review_2022}. Deep-Learning-Modelle bieten in der Regel eine höhere Genauigkeit bei Aufgaben wie Objektdetektion, Segmentierung und Klassifikation, da sie aus großen Datensätzen lernen können. Sie können komplexe Muster in den Daten erfassen, die von traditionellen Methoden oft übersehen werden \cite{zhao_object_2019}. Zudem können Deep-Learning-Modelle so trainiert werden, dass sie robust gegenüber Variationen in Bildqualität, Beleuchtung und Hintergrundrauschen sind, was häufige Probleme bei traditionellen Bildverarbeitungsmethoden sind \cite{liu_deep_2023}.Diese Vorteile sind direkt relevant für die Herausforderungen, denen ich in meiner praktischen Arbeit begegnet bin.

\section{Problemstellung}
Das Training neuronaler Netze erfordert üblicherweise eine große Anzahl annotierter Bilder mit geeignetem Kontext. In der industriellen Qualitätskontrolle steht jedoch oft nur eine begrenzte Anzahl spezifischer, fehlerhafter und fehlerfreier Musterteile zur Verfügung. Da es für jeden Anwendungsfall keine öffentlich zugänglichen Datensätze gibt, entsteht ein relativ kleiner Datensatz, dessen zu detektierende Regionen manuell annotiert werden müssen. Dieser Mangel an umfangreichen und vielfältigen Trainingsdaten stellt eine erhebliche Herausforderung dar.

Diese Einschränkungen führen dazu, dass für das Training eines Deep-Learning-Modells nur sehr wenige Bilder verfügbar sind, was Probleme wie Overfitting begünstigen kann. Das Modell neigt dazu, die Trainingsdaten zu überanpassen und generalisiert schlecht auf neue, unbekannte Daten.\cite{lecun_deep_2015}

Vor diesem Hintergrund stellt sich die Frage, wie eine effektive semantische Segmentierung in der industriellen Qualitätskontrolle trotz begrenzter Datenmenge erreicht werden kann.

Eine vielversprechende Lösung bietet die U-Net-Architektur, die sich in der Literatur als geeignet für die semantische Segmentierung komplexer Bilddaten erwiesen hat. U-Net stützt sich intensiv auf Datenaugmentation, um die begrenzte Anzahl annotierter Beispiele effizient zu nutzen. Das Netzwerk wird mit sehr wenigen Bildern trainiert und zeigt dennoch eine überlegene Leistung bei Aufgaben der biomedizinischen Bildsegmentierung \cite{ronneberger_u-net_2015}. Diese Eigenschaften machen U-Net zu einem idealen Kandidaten für Anwendungen in der industriellen Qualitätskontrolle, bei denen nur eingeschränkte Trainingsdaten verfügbar sind.

In den letzten Jahren wurde die U-Net-Architektur erfolgreich in verschiedenen Bereichen der Medizin eingesetzt\cite{azad_medical_2024,siddique_u-net_2021}. Ihre Anpassungsfähigkeit und Effizienz bei der Verarbeitung komplexer Bilddaten unter schwierigen Bedingungen legen nahe, dass sie auch für die Herausforderungen in der industriellen Bildverarbeitung geeignet sein könnte.
